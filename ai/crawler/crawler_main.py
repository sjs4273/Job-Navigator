"""
sequenceDiagram
  participant Main as ğŸ§  crawler_main.py
  participant Crawler as ğŸ“¡ jumpit_crawler.py
  participant DBSave as ğŸ’¾ save_jobs.py
  participant Mark as ğŸš« mark_closed.py

  Main->>Crawler: get_jumpit_jobs()
  Crawler-->>Main: ì±„ìš© ê³µê³  ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (List[Dict])

  Main->>DBSave: save_jobs_to_db(jobs)
  DBSave-->>Main: ì €ì¥ ì™„ë£Œ

  Main->>Mark: mark_closed_jobs(url_list)
  Mark-->>Main: ë§ˆê° ì²˜ë¦¬ ì™„ë£Œ
"""

# ğŸš€ í¬ë¡¤ë§ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

# ğŸ“¡ Jumpit ì‚¬ì´íŠ¸ì—ì„œ ì±„ìš©ê³µê³  í¬ë¡¤ë§ í•¨ìˆ˜
from services.jumpit_crawler import get_jumpit_jobs

# ğŸ’¾ ìˆ˜ì§‘í•œ ê³µê³ ë¥¼ DBì— ì €ì¥ (ì‹ ê·œ/ì—…ë°ì´íŠ¸ êµ¬ë¶„)
from repository.save_jobs import save_jobs_to_db

# ğŸš« DBì— ì €ì¥ëœ ê³µê³  ì¤‘, í˜„ì¬ í˜ì´ì§€ì—ì„œ ì‚¬ë¼ì§„ ê³µê³ ë¥¼ ë§ˆê°ì²˜ë¦¬
from repository.mark_closed import mark_closed_jobs


def main():
    print("ğŸ“¡ Jumpit ì±„ìš© ê³µê³  ìˆ˜ì§‘ ì‹œì‘")
    jobs = get_jumpit_jobs()  # â¬…ï¸ ì±„ìš©ê³µê³  ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§
    print(f"ğŸ“¦ ìˆ˜ì§‘ëœ ê³µê³  ìˆ˜: {len(jobs)}ê°œ")

    print("ğŸ’¾ DB ì €ì¥ ì‹œì‘")
    save_jobs_to_db(jobs)  # â¬…ï¸ DBì— insert/update ì²˜ë¦¬

    print("ğŸ“› ë§ˆê°ëœ ê³µê³  ì²˜ë¦¬ ì‹œì‘")
    latest_urls = [job["url"] for job in jobs]
    mark_closed_jobs(latest_urls)  # â¬…ï¸ DB ë‚´ ê¸°ì¡´ ê³µê³  ì¤‘ ì‚¬ë¼ì§„ ê³µê³  ë§ˆê° ì²˜ë¦¬

    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ")


if __name__ == "__main__":
    main()
