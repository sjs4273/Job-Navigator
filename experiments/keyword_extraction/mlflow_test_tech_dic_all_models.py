# mlflow_test_tech_all_models.py
"""
ì„¸ ê°€ì§€ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ ëª¨ë¸(ëŒ€ì‚¬ì „, ì†Œì‚¬ì „, ë™ì˜ì–´ ë§¤í•‘)ì„
í•œ íŒŒì¼ì—ì„œ MLflowë¥¼ ì´ìš©í•´ í‰ê°€í•˜ëŠ” í†µí•© ì‹¤í—˜ ì½”ë“œì…ë‹ˆë‹¤.

- DictionaryFullTechSkill: ì „ì²´ ê¸°ìˆ  í‚¤ì›Œë“œ ëŒ€ì‚¬ì „ ê¸°ë°˜ ì¶”ì¶œ
- DictionaryReducedKeywords: ë¶„ì•¼ë³„ ëŒ€í‘œ ê¸°ìˆ ëª… ì†Œì‚¬ì „ ê¸°ë°˜ ì¶”ì¶œ
- DictionaryFullEquivalents: ë™ì˜ì–´/ì˜¤íƒˆì í¬í•¨ í‘œì¤€ëª… ë§¤í•‘ ëª¨ë¸
"""

import json
import re
from tqdm import tqdm
import mlflow
import nltk
from typing import List

from mlflow_test_tech_dict import FULL_TECH_STACK, REDUCED_TECH_KEYWORDS, TECH_EQUIVALENTS

# nltk í† í°í™” íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ (ì‹¤í—˜ì‹œ í•„ìš”í•œ ê²½ìš°)
nltk.download("punkt", quiet=True)

def load_dataset(path: str):
    """
    JSONL í˜•ì‹ì˜ ë°ì´í„°ì…‹ íŒŒì¼ì„ ì½ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    with open(path, "r", encoding="utf-8") as f:
        return [json.loads(line) for line in f]

def extract_keywords_full_tech_stack(text: str, tech_stack: List[str]) -> List[str]:
    """
    ëŒ€ì‚¬ì „(FULL_TECH_STACK) ê¸°ë°˜ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ
    - ë‹¨ì–´ ê²½ê³„, ì¡°ì‚¬, ê³µë°±, êµ¬ë‘ì  ë“±ì„ ê³ ë ¤í•´ robustí•˜ê²Œ ë§¤ì¹­
    """
    found_keywords = set()
    lowered_text = text.lower()
    for keyword in tech_stack:
        patterns = [
            rf"\b{re.escape(keyword.lower())}\b",                   # ì™„ì „ ë‹¨ì–´ ë§¤ì¹­
            rf"{re.escape(keyword.lower())}(?=[ì„ë¥¼ì´ê°€ëŠ”ì€ì—ì„œì™€ê³¼])", # ì¡°ì‚¬ ë’¤ì— ì˜¤ëŠ” ê²½ìš°
            rf"{re.escape(keyword.lower())}(?=\s)",                 # ê³µë°± ë’¤
            rf"{re.escape(keyword.lower())}(?=[.,!?])",             # êµ¬ë‘ì  ì•
        ]
        if any(re.search(p, lowered_text) for p in patterns):
            found_keywords.add(keyword)
    return sorted(found_keywords)

def extract_keywords_reduced(text: str) -> List[str]:
    """
    ì†Œì‚¬ì „(REDUCED_TECH_KEYWORDS) ê¸°ë°˜ ê¸°ìˆ  í‚¤ì›Œë“œ ì¶”ì¶œ
    - ë¶„ì•¼ë³„ ëŒ€í‘œ ê¸°ìˆ ëª… ì¹´í…Œê³ ë¦¬ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì¶”ì¶œ
    """
    found_keywords = set()
    lowered_text = text.lower()
    for category_keywords in REDUCED_TECH_KEYWORDS.values():
        for keyword in category_keywords:
            k = keyword.lower()
            patterns = [
                r'\b' + re.escape(k) + r'\b',
                re.escape(k) + r'(?=[ì„ë¥¼ì´ê°€ëŠ”ì€ì—ì„œì™€ê³¼])',
                re.escape(k) + r'(?=\s)',
                re.escape(k) + r'(?=[.,!?])',
            ]
            if any(re.search(p, lowered_text) for p in patterns):
                found_keywords.add(keyword)
    return sorted(found_keywords)

def extract_keywords_full_equivalents(text: str, equivalents_dict) -> List[str]:
    """
    ë™ì˜ì–´/ì˜¤íƒˆì í¬í•¨ í‘œì¤€ ê¸°ìˆ ëª… ë°˜í™˜ ëª¨ë¸
    - í‘œì¤€ ê¸°ìˆ ëª… í‚¤ì™€ ê·¸ ë³€í˜•(alias)ë“¤ì„ ë§¤ì¹­í•´ í‘œì¤€ëª…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ì¶œ
    """
    found_keywords = set()
    lowered_text = text.lower()
    for standard, variants in equivalents_dict.items():
        for alias in variants:
            a = alias.lower()
            patterns = [
                r'\b' + re.escape(a) + r'\b',
                re.escape(a) + r'(?=[ì„ë¥¼ì´ê°€ëŠ”ì€ì—ì„œì™€ê³¼])',
                re.escape(a) + r'(?=\s)',
                re.escape(a) + r'(?=[.,!?])',
            ]
            if any(re.search(p, lowered_text) for p in patterns):
                found_keywords.add(standard)  # í‘œì¤€ëª…ìœ¼ë¡œ ì¶”ê°€
                break
    return sorted(found_keywords)

def evaluate(pred, gold):
    """
    ì˜ˆì¸¡(pred)ê³¼ ì •ë‹µ(gold) í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„°
    Precision, Recall, F1 Score ê³„ì‚° ë°˜í™˜
    """
    p_set, g_set = set(pred), set(gold)
    tp = len(p_set & g_set)  # True Positive
    fp = len(p_set - g_set)  # False Positive
    fn = len(g_set - p_set)  # False Negative
    precision = tp / (tp + fp + 1e-10)  # ì •ë°€ë„
    recall = tp / (tp + fn + 1e-10)     # ì¬í˜„ìœ¨
    f1 = 2 * precision * recall / (precision + recall + 1e-10)  # F1 ìŠ¤ì½”ì–´
    return precision, recall, f1

def save_simple_predicted_keywords(samples, predictions, output_path="predicted_keywords_simple.txt"):
    """
    ì •ë‹µ í‚¤ì›Œë“œì™€ ì˜ˆì¸¡ í‚¤ì›Œë“œë¥¼ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    """
    with open(output_path, "w", encoding="utf-8") as f:
        for sample, pred in zip(samples, predictions):
            true_str = ", ".join(sample["keywords"])
            pred_str = ", ".join(pred)
            f.write(f"[ì •ë‹µ] {true_str}\n")
            f.write(f"[ì˜ˆì¸¡] {pred_str}\n")
            f.write("-----\n")
    print(f"ê°„ë‹¨ í˜•ì‹ ì˜ˆì¸¡ ê²°ê³¼ê°€ '{output_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def run_experiment(dataset_path: str, models: list):
    """
    ë°ì´í„°ì…‹ ê²½ë¡œì™€ ì‹¤í–‰í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ MLflow ì‹¤í—˜ ì‹¤í–‰
    """
    data = load_dataset(dataset_path)
    mlflow.set_experiment("ShortSentenceKeywordExtraction")

    for model_name in models:
        # ëª¨ë¸ë³„ ì¶”ì¶œ í•¨ìˆ˜, ì„¤ëª…, ì‚¬ì „ í¬ê¸°, ëŸ° ì´ë¦„ ì„¤ì •
        if model_name == "DictionaryFullTechSkill":
            extract_func = lambda text: extract_keywords_full_tech_stack(text, FULL_TECH_STACK)
            model_desc = "ì „ì²´ ê¸°ìˆ  í‚¤ì›Œë“œ ì‚¬ì „(FULL_TECH_STACK) ê¸°ë°˜, ëŒ€ì‚¬ì „"
            tech_stack_size = len(FULL_TECH_STACK)
            run_name = "[Full] FullTechSkill"
        elif model_name == "DictionaryReducedKeywords":
            extract_func = extract_keywords_reduced
            model_desc = "ë¶„ì•¼ë³„ ëŒ€í‘œ ê¸°ìˆ ëª…ë§Œ (REDUCED_TECH_KEYWORDS ê¸°ë°˜, ì†Œì‚¬ì „)"
            tech_stack_size = sum(len(v) for v in REDUCED_TECH_KEYWORDS.values())
            run_name = "[Reduce] Representative only"
        elif model_name == "DictionaryFullEquivalents":
            extract_func = lambda text: extract_keywords_full_equivalents(text, TECH_EQUIVALENTS)
            model_desc = "ë™ì˜ì–´/ë³€í˜•/ì˜¤íƒˆì í¬í•¨ (TECH_EQUIVALENTS ê¸°ë°˜, í‘œì¤€ ê¸°ìˆ ëª… ë°˜í™˜)"
            tech_stack_size = len(TECH_EQUIVALENTS)
            run_name = "[Full] Synonym/Eq-mapping"
        else:
            raise ValueError(f"Unknown model: {model_name}")

        # MLflow Run ì‹œì‘
        with mlflow.start_run(run_name=run_name, description=model_desc):
            mlflow.log_param("model_name", model_name)
            mlflow.log_param("run_name", run_name)
            mlflow.log_param("stack_label", model_name)
            mlflow.log_param("model_desc", model_desc)
            mlflow.log_param("tech_stack_size", tech_stack_size)

            ps, rs, f1s = [], [], []
            results = []
            all_predictions = []

            # ë°ì´í„°ì…‹ í•­ëª©ë³„ ì˜ˆì¸¡ ë° í‰ê°€ ìˆ˜í–‰
            for item in tqdm(data, desc=f"[{model_name}]"):
                sent, gold = item["sentence"], item["keywords"]
                pred = extract_func(sent)
                all_predictions.append(pred)
                p, r, f1 = evaluate(pred, gold)
                ps.append(p)
                rs.append(r)
                f1s.append(f1)
                results.append({
                    "sentence": sent,
                    "true_keywords": gold,
                    "predicted_keywords": pred,
                    "precision": round(p, 4),
                    "recall": round(r, 4),
                    "f1": round(f1, 4)
                })

            # í‰ê·  ì§€í‘œ ê³„ì‚°
            avg_p = sum(ps) / len(ps)
            avg_r = sum(rs) / len(rs)
            avg_f1 = sum(f1s) / len(f1s)

            # MLflowì— í‰ê·  ì§€í‘œ ê¸°ë¡
            mlflow.log_metric("avg_precision", avg_p)
            mlflow.log_metric("avg_recall", avg_r)
            mlflow.log_metric("avg_f1", avg_f1)

            # ê²°ê³¼ JSONL íŒŒì¼ ì €ì¥ ë° MLflow ì•„í‹°íŒ©íŠ¸ ë“±ë¡
            result_path_jsonl = f"predicted_keywords_{model_name}.jsonl"
            with open(result_path_jsonl, "w", encoding="utf-8") as f_jsonl:
                for item in results:
                    f_jsonl.write(json.dumps(item, ensure_ascii=False) + "\n")
            mlflow.log_artifact(result_path_jsonl)

            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì •ë‹µ/ì˜ˆì¸¡ í‚¤ì›Œë“œ ì €ì¥ ë° ì•„í‹°íŒ©íŠ¸ ë“±ë¡
            result_path_txt = f"predicted_keywords_simple_{model_name}.txt"
            save_simple_predicted_keywords(data, all_predictions, result_path_txt)
            mlflow.log_artifact(result_path_txt)

            # ì½˜ì†” ì¶œë ¥
            print(f"\nğŸ“Š [{run_name}] ({model_desc}) ê²°ê³¼  P={avg_p:.4f}  R={avg_r:.4f}  F1={avg_f1:.4f}")

if __name__ == "__main__":
    models_to_run = [
        "DictionaryFullTechSkill",
        "DictionaryReducedKeywords",
        "DictionaryFullEquivalents"
    ]
    print("ğŸš€ Starting Combined TECH Stack Dictionary Evaluation...")
    print(f"ğŸ¯ Testing models: {models_to_run}")
    run_experiment("data/keywords_dataset.v2.jsonl", models=models_to_run)
