# backend/app/services/keyword_service.py

import os
import uuid
import shutil
import logging
from fastapi import UploadFile
from sqlalchemy.orm import Session
from ai.extractor import extract_keywords_from_pdf  # AI í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
from app.core.database import SessionLocal
from app.models.resume import ResumeORM
from app.models.user import UserORM

logger = logging.getLogger(__name__)

async def extract_and_save_keywords(current_user: UserORM, pdf_file: UploadFile) -> ResumeORM:
    """
    PDF íŒŒì¼ì„ ì €ì¥í•œ í›„ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³ , ê´€ë ¨ ì •ë³´ë¥¼ Resume í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.

    Parameters:
        current_user (UserORM): ì¸ì¦ëœ ì‚¬ìš©ì ê°ì²´
        pdf_file (UploadFile): ì—…ë¡œë“œëœ PDF íŒŒì¼ ê°ì²´

    Returns:
        ResumeORM: ì €ì¥ëœ ì´ë ¥ì„œ ORM ê°ì²´
    """
    # 1. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    file_id = str(uuid.uuid4())
    filename = pdf_file.filename
    temp_dir = "./temp"
    os.makedirs(temp_dir, exist_ok=True)
    file_path = os.path.join(temp_dir, f"{file_id}_{filename}")

    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(pdf_file.file, buffer)

    logger.info(f"ğŸ“„ PDF ì €ì¥ ì™„ë£Œ: {file_path}")

    # 2. AI í‚¤ì›Œë“œ ì¶”ì¶œ
    with open(file_path, "rb") as f:
        file_bytes = f.read()
    keywords = extract_keywords_from_pdf(file_bytes)

    logger.info(f"ğŸ§  í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼: {keywords}")

    # 3. DB ì €ì¥
    db: Session = SessionLocal()
    try:
        resume_entry = ResumeORM(
            user_id=current_user.user_id,
            file_path=file_path,
            extracted_keywords=keywords,
            job_category="",  # ë¶„ë¥˜ ê²°ê³¼ëŠ” ì•„ì§ ì—†ìŒ
        )
        db.add(resume_entry)
        db.commit()
        db.refresh(resume_entry)  # ì €ì¥ëœ ORM ê°ì²´ ì •ë³´ ìµœì‹ í™”
        return resume_entry       # âœ… ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜í•˜ëŠ” ORM ê°ì²´ ë°˜í™˜
    except Exception as e:
        db.rollback()
        logger.error("âŒ Resume ì €ì¥ ì‹¤íŒ¨", exc_info=True)
        raise e
    finally:
        db.close()

